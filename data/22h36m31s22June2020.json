{
   "notes": "This plot would challenge the view that networks which train well end up in similar locations in parameter space. There are three networks which all improve and remain in a similar area to where they began. Perhaps improvement is based on dynamics and interplay between individual layers rather than entire network weights as a whole",
   "training_iterations": 15,
   "projection_model": "AutoEncoder",
   "train_projection_model_on_first_only": false,
   "number_of_networks": 3,
   "network_parameters": {
      "hidden_layer_sizes": [
         8,
         8,
         8,
         8,
         8
      ],
      "activation": "relu",
      "alpha": 0.0001,
      "solver": "sgd",
      "learning_rate_init": 0.1
   },
   "layer_to_track": null,
   "average_hidden_layers": false,
   "track_first_n_layers_separately": null
}